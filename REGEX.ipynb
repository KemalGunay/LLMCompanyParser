{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MerchantDataExtractor:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        self.merchants = []\n",
    "        \n",
    "    def extract_merchants(self) -> List[Dict]:\n",
    "        \"\"\"Ana extraction metodu\"\"\"\n",
    "        # Merchants bölümünü bul\n",
    "        merchants_section = self._extract_merchants_section()\n",
    "        \n",
    "        # Her şirketi parse et\n",
    "        companies = self._split_into_companies(merchants_section)\n",
    "        \n",
    "        for company_text in companies:\n",
    "            merchant_data = self._parse_company(company_text)\n",
    "            if merchant_data and merchant_data.get('company_name'):\n",
    "                self.merchants.append(merchant_data)\n",
    "        \n",
    "        return self.merchants\n",
    "    \n",
    "    def _extract_merchants_section(self) -> str:\n",
    "        \"\"\"Merchants bölümünü çıkart\"\"\"\n",
    "        # \"Merchants\" ile başlayan ve \"Suppliers\" ile biten bölümü al\n",
    "        pattern = r'Merchants\\s+BMF Handbook.*?(?=Suppliers|Service Providers|$)'\n",
    "        match = re.search(pattern, self.text, re.DOTALL)\n",
    "        \n",
    "        if match:\n",
    "            return match.group(0)\n",
    "        return self.text\n",
    "    \n",
    "    def _split_into_companies(self, text: str) -> List[str]:\n",
    "        \"\"\"Metni şirketlere böl\"\"\"\n",
    "        companies = []\n",
    "        \n",
    "        # Şirket isimlerini bul - genellikle bold ve sol hizada\n",
    "        # Core Activity'den önceki satırları şirket ismi olarak kabul et\n",
    "        pattern = r'([A-Z][^\\n]{10,100})\\n([^\\n]+(?:\\n[^\\n]+)*?)\\nCore Activity'\n",
    "        \n",
    "        matches = re.finditer(pattern, text, re.MULTILINE)\n",
    "        \n",
    "        current_pos = 0\n",
    "        for match in matches:\n",
    "            if current_pos > 0:\n",
    "                # Önceki şirketin metnini al\n",
    "                company_text = text[current_pos:match.start()]\n",
    "                companies.append(company_text)\n",
    "            current_pos = match.start()\n",
    "        \n",
    "        # Son şirketi ekle\n",
    "        if current_pos > 0:\n",
    "            companies.append(text[current_pos:])\n",
    "        \n",
    "        return companies if companies else [text]\n",
    "    \n",
    "    def _parse_company(self, text: str) -> Dict:\n",
    "        \"\"\"Tek bir şirketi parse et\"\"\"\n",
    "        data = {\n",
    "            'company_name': '',\n",
    "            'address': '',\n",
    "            'city': '',\n",
    "            'postcode': '',\n",
    "            'country': '',\n",
    "            'phone': '',\n",
    "            'fax': '',\n",
    "            'email': '',\n",
    "            'website': '',\n",
    "            'core_activity': '',\n",
    "            'branches': []\n",
    "        }\n",
    "        \n",
    "        lines = text.strip().split('\\n')\n",
    "        lines = [l.strip() for l in lines if l.strip()]\n",
    "        \n",
    "        if not lines:\n",
    "            return data\n",
    "        \n",
    "        # Şirket ismini al (genellikle ilk satır)\n",
    "        data['company_name'] = lines[0]\n",
    "        \n",
    "        # Adres bilgilerini parse et\n",
    "        address_parts = []\n",
    "        i = 1\n",
    "        \n",
    "        while i < len(lines):\n",
    "            line = lines[i]\n",
    "            \n",
    "            # Core Activity bulundu mu?\n",
    "            if line.startswith('Core Activity'):\n",
    "                data['core_activity'] = line.replace('Core Activity', '').strip()\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Branches bulundu mu?\n",
    "            if line == 'Branches' or line.startswith('Branches'):\n",
    "                i += 1\n",
    "                # Branch bilgilerini topla\n",
    "                branches = self._parse_branches(lines[i:])\n",
    "                data['branches'] = branches\n",
    "                break\n",
    "            \n",
    "            # Telefon\n",
    "            if line.startswith('T '):\n",
    "                data['phone'] = line.replace('T ', '').strip()\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Fax\n",
    "            if line.startswith('F '):\n",
    "                data['fax'] = line.replace('F ', '').strip()\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Email\n",
    "            if line.startswith('E '):\n",
    "                data['email'] = line.replace('E ', '').strip()\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Website\n",
    "            if line.startswith('W '):\n",
    "                data['website'] = line.replace('W ', '').strip()\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Adres satırı olarak kabul et\n",
    "            address_parts.append(line)\n",
    "            i += 1\n",
    "        \n",
    "        # Adres parçalarından bilgileri çıkar\n",
    "        if address_parts:\n",
    "            full_address = ', '.join(address_parts)\n",
    "            data['address'] = full_address\n",
    "            \n",
    "            # Ülke (genellikle England, Scotland, Wales, Northern Ireland)\n",
    "            country_pattern = r'\\b(England|Scotland|Wales|Northern Ireland|Ireland)\\b'\n",
    "            country_match = re.search(country_pattern, full_address)\n",
    "            if country_match:\n",
    "                data['country'] = country_match.group(1)\n",
    "            \n",
    "            # Postcode (UK postcode pattern)\n",
    "            postcode_pattern = r'\\b([A-Z]{1,2}\\d{1,2}[A-Z]?\\s?\\d[A-Z]{2})\\b'\n",
    "            postcode_match = re.search(postcode_pattern, full_address)\n",
    "            if postcode_match:\n",
    "                data['postcode'] = postcode_match.group(1)\n",
    "            \n",
    "            # Şehir (postcode'dan önceki kelime genellikle şehir)\n",
    "            if data['postcode']:\n",
    "                city_pattern = rf'([^,]+),\\s*{re.escape(data[\"country\"])}'\n",
    "                city_match = re.search(city_pattern, full_address)\n",
    "                if city_match:\n",
    "                    data['city'] = city_match.group(1).strip()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _parse_branches(self, lines: List[str]) -> List[Dict]:\n",
    "        \"\"\"Branch bilgilerini parse et\"\"\"\n",
    "        branches = []\n",
    "        current_branch = None\n",
    "        \n",
    "        for line in lines:\n",
    "            # Yeni bir branch başlıyor mu? (T ile başlamıyorsa)\n",
    "            if not line.startswith('T ') and not line.startswith('F ') and not line.startswith('E '):\n",
    "                # Önceki branch'i kaydet\n",
    "                if current_branch and current_branch.get('name'):\n",
    "                    branches.append(current_branch)\n",
    "                \n",
    "                # Yeni branch başlat\n",
    "                current_branch = {\n",
    "                    'name': line,\n",
    "                    'phone': '',\n",
    "                    'fax': '',\n",
    "                    'email': ''\n",
    "                }\n",
    "            else:\n",
    "                if current_branch:\n",
    "                    if line.startswith('T '):\n",
    "                        current_branch['phone'] = line.replace('T ', '').strip()\n",
    "                    elif line.startswith('F '):\n",
    "                        current_branch['fax'] = line.replace('F ', '').strip()\n",
    "                    elif line.startswith('E '):\n",
    "                        current_branch['email'] = line.replace('E ', '').strip()\n",
    "        \n",
    "        # Son branch'i ekle\n",
    "        if current_branch and current_branch.get('name'):\n",
    "            branches.append(current_branch)\n",
    "        \n",
    "        return branches\n",
    "    \n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"Ana firma bilgilerini DataFrame'e çevir\"\"\"\n",
    "        if not self.merchants:\n",
    "            self.extract_merchants()\n",
    "        \n",
    "        main_data = []\n",
    "        for merchant in self.merchants:\n",
    "            main_data.append({\n",
    "                'Company Name': merchant['company_name'],\n",
    "                'Address': merchant['address'],\n",
    "                'City': merchant['city'],\n",
    "                'Postcode': merchant['postcode'],\n",
    "                'Country': merchant['country'],\n",
    "                'Phone': merchant['phone'],\n",
    "                'Fax': merchant['fax'],\n",
    "                'Email': merchant['email'],\n",
    "                'Website': merchant['website'],\n",
    "                'Core Activity': merchant['core_activity'],\n",
    "                'Number of Branches': len(merchant['branches'])\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(main_data)\n",
    "    \n",
    "    def branches_to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"Branch bilgilerini ayrı bir DataFrame'e çevir\"\"\"\n",
    "        if not self.merchants:\n",
    "            self.extract_merchants()\n",
    "        \n",
    "        branches_data = []\n",
    "        for merchant in self.merchants:\n",
    "            company_name = merchant['company_name']\n",
    "            for branch in merchant['branches']:\n",
    "                branches_data.append({\n",
    "                    'Company Name': company_name,\n",
    "                    'Branch Name': branch['name'],\n",
    "                    'Branch Phone': branch['phone'],\n",
    "                    'Branch Fax': branch['fax'],\n",
    "                    'Branch Email': branch['email']\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(branches_data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Ana çalıştırma fonksiyonu\"\"\"\n",
    "    \n",
    "    # PDF'den çıkarttığınız metni buraya yapıştırın\n",
    "    # Örnek: text = open('merchants_text.txt', 'r', encoding='utf-8').read()\n",
    "    \n",
    "    # Sizin verdiğiniz metni kullanalım\n",
    "    text = \"\"\"\n",
    "    [PDF'den çıkardığınız metni buraya yapıştırın]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Veri çıkartma başlıyor...\")\n",
    "    \n",
    "    # Extractor'ı oluştur\n",
    "    extractor = MerchantDataExtractor(text)\n",
    "    \n",
    "    # Verileri çıkart\n",
    "    merchants = extractor.extract_merchants()\n",
    "    print(f\"Toplam {len(merchants)} şirket bulundu.\")\n",
    "    \n",
    "    # Ana firma bilgilerini DataFrame'e çevir\n",
    "    df_main = extractor.to_dataframe()\n",
    "    print(f\"\\nAna firma bilgileri: {len(df_main)} kayıt\")\n",
    "    print(df_main.head())\n",
    "    \n",
    "    # Branch bilgilerini DataFrame'e çevir\n",
    "    df_branches = extractor.branches_to_dataframe()\n",
    "    print(f\"\\nBranch bilgileri: {len(df_branches)} kayıt\")\n",
    "    print(df_branches.head())\n",
    "    \n",
    "    # CSV'ye kaydet\n",
    "    df_main.to_csv('merchants_main.csv', index=False, encoding='utf-8-sig')\n",
    "    df_branches.to_csv('merchants_branches.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"\\n✅ Veriler başarıyla kaydedildi!\")\n",
    "    print(\"📁 merchants_main.csv - Ana firma bilgileri\")\n",
    "    print(\"📁 merchants_branches.csv - Branch bilgileri\")\n",
    "    \n",
    "    return df_main, df_branches\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_main, df_branches = main()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:07:02.664420Z",
     "start_time": "2025-10-28T18:06:49.614550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_from_pdf(pdf_path: str):\n",
    "    \"\"\"PDF'den direkt veri çıkart\"\"\"\n",
    "    \n",
    "    full_text = \"\"\n",
    "    \n",
    "    # PDF'i oku\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                full_text += text + \"\\n\"\n",
    "    \n",
    "    # Extractor ile işle\n",
    "    extractor = MerchantDataExtractor(full_text)\n",
    "    merchants = extractor.extract_merchants()\n",
    "    \n",
    "    # DataFrame'lere çevir\n",
    "    df_main = extractor.to_dataframe()\n",
    "    df_branches = extractor.branches_to_dataframe()\n",
    "    \n",
    "    # Kaydet\n",
    "    df_main.to_csv('merchants_main.csv', index=False, encoding='utf-8-sig')\n",
    "    df_branches.to_csv('merchants_branches.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return df_main, df_branches\n",
    "\n",
    "# Kullanım\n",
    "df_main, df_branches = extract_from_pdf('/Users/kemalgunay/Desktop/VERI_BILIMI/PDF-SCRAPER/ISMAIL-PDF-PARSER/BMF-23-Just-Comps.pdf')"
   ],
   "id": "68041ce37158aa42",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:06:47.606074Z",
     "start_time": "2025-10-28T18:06:44.422959Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pdfplumber",
   "id": "90bf018721cf1f5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\r\n",
      "  Obtaining dependency information for pdfplumber from https://files.pythonhosted.org/packages/db/e0/52b67d4f00e09e497aec4f71bc44d395605e8ebcea52543242ed34c25ef9/pdfplumber-0.11.7-py3-none-any.whl.metadata\r\n",
      "  Using cached pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\r\n",
      "Collecting pdfminer.six==20250506 (from pdfplumber)\r\n",
      "  Obtaining dependency information for pdfminer.six==20250506 from https://files.pythonhosted.org/packages/73/16/7a432c0101fa87457e75cb12c879e1749c5870a786525e2e0f42871d6462/pdfminer_six-20250506-py3-none-any.whl.metadata\r\n",
      "  Using cached pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting Pillow>=9.1 (from pdfplumber)\r\n",
      "  Obtaining dependency information for Pillow>=9.1 from https://files.pythonhosted.org/packages/fd/e0/ed960067543d080691d47d6938ebccbf3976a931c9567ab2fbfab983a5dd/pillow-12.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached pillow-12.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.8 kB)\r\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\r\n",
      "  Obtaining dependency information for pypdfium2>=4.18.0 from https://files.pythonhosted.org/packages/13/bf/4259b23a88b92bec8199e1a08a0821dbfbb465629c203bdbc49e2f993940/pypdfium2-5.0.0-py3-none-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached pypdfium2-5.0.0-py3-none-macosx_11_0_arm64.whl.metadata (67 kB)\r\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./.venv/lib/python3.12/site-packages (from pdfminer.six==20250506->pdfplumber) (3.4.4)\r\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->pdfplumber)\r\n",
      "  Obtaining dependency information for cryptography>=36.0.0 from https://files.pythonhosted.org/packages/1d/42/9c391dd801d6cf0d561b5890549d4b27bafcc53b39c31a817e69d87c625b/cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl.metadata\r\n",
      "  Using cached cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\r\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\r\n",
      "Using cached pdfplumber-0.11.7-py3-none-any.whl (60 kB)\r\n",
      "Using cached pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\r\n",
      "Using cached pillow-12.0.0-cp312-cp312-macosx_11_0_arm64.whl (4.7 MB)\r\n",
      "Using cached pypdfium2-5.0.0-py3-none-macosx_11_0_arm64.whl (2.8 MB)\r\n",
      "Using cached cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\r\n",
      "Installing collected packages: pypdfium2, Pillow, cryptography, pdfminer.six, pdfplumber\r\n",
      "Successfully installed Pillow-12.0.0 cryptography-46.0.3 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-5.0.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9a4c2f6765b983e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:13:03.424929Z",
     "start_time": "2025-10-28T18:12:50.385399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "PDF_PATH = \"/Users/kemalgunay/Desktop/VERI_BILIMI/PDF-SCRAPER/ISMAIL-PDF/BMF-23-Just-Comps.pdf\"\n",
    "OUTPUT_MAIN = \"merchants_main.csv\"\n",
    "OUTPUT_BRANCHES = \"merchants_branches.csv\"\n",
    "\n",
    "# -----------------------\n",
    "# Yardımcı regex'ler\n",
    "# -----------------------\n",
    "PHONE_RE = re.compile(r'(?:T|Tel|Phone|T\\.)[:\\s]*(\\+?\\d[\\d\\-\\s\\(\\)\\/]{5,}\\d)')\n",
    "EMAIL_RE = re.compile(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+')\n",
    "WWW_RE = re.compile(r'(https?://[^\\s,;]+|www\\.[^\\s,;]+|[^\\s,;]+\\.co\\.uk|[^\\s,;]+\\.com|[^\\s,;]+\\.net)')\n",
    "CORE_ACTIVITY_RE = re.compile(r'Core Activity[:\\s\\-]*([A-Za-z0-9 \\&\\,\\-]+)', re.IGNORECASE)\n",
    "BRANCHES_HEADER_RE = re.compile(r'Branches', re.IGNORECASE)\n",
    "\n",
    "# -----------------------\n",
    "# 1) PDF -> sütun bazlı metin blokları\n",
    "# -----------------------\n",
    "def extract_column_blocks(pdf_path: str, n_cols: int = 3) -> List[str]:\n",
    "    \"\"\"Her sayfada sütunlara göre sözcükleri grupla, satırları toparla, sütun sırasına göre blok listesi döndür.\"\"\"\n",
    "    blocks = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in tqdm(pdf.pages, desc=\"Pages\"):\n",
    "            # page width\n",
    "            w = page.width\n",
    "            # eşit üç sütun varsayımı (pdf görselde eşit sütunlar)\n",
    "            col_width = w / n_cols\n",
    "            # sayfadaki tüm kelimeleri al\n",
    "            words = page.extract_words(use_text_flow=True, keep_blank_chars=False)\n",
    "            # her kelimeyi (x0,x1,y0,y1,text) -> sütun id'ye ata\n",
    "            cols = [[] for _ in range(n_cols)]\n",
    "            for wd in words:\n",
    "                x0 = float(wd.get(\"x0\", 0))\n",
    "                col_idx = min(int(x0 // col_width), n_cols-1)\n",
    "                cols[col_idx].append(wd)\n",
    "            # her sütunda kelimeleri y koordinatına göre gruplaçizgiler oluştur\n",
    "            for c in range(n_cols):\n",
    "                if not cols[c]:\n",
    "                    continue\n",
    "                # grup by y0 (satır oluşturma)\n",
    "                # satır eşiği: küçük bir delta ile aynı satır kabul et\n",
    "                rows = []\n",
    "                cols[c].sort(key=lambda x: (x[\"top\"], x[\"x0\"]))\n",
    "                current_y = None\n",
    "                current_line = []\n",
    "                for wdict in cols[c]:\n",
    "                    y = round(float(wdict[\"top\"]), 1)\n",
    "                    if current_y is None:\n",
    "                        current_y = y\n",
    "                        current_line = [wdict[\"text\"]]\n",
    "                    else:\n",
    "                        if abs(y - current_y) <= 3:  # aynı satır\n",
    "                            current_line.append(wdict[\"text\"])\n",
    "                        else:\n",
    "                            rows.append(\" \".join(current_line))\n",
    "                            current_y = y\n",
    "                            current_line = [wdict[\"text\"]]\n",
    "                if current_line:\n",
    "                    rows.append(\" \".join(current_line))\n",
    "                # satırlardaki büyük boşluklarla (başka blok) ayır; boşluk varsa yeni blok\n",
    "                # bir sayfa sütunundaki metni tek string halinde blok olarak sakla\n",
    "                col_text = \"\\n\".join(rows).strip()\n",
    "                if col_text:\n",
    "                    blocks.append(col_text)\n",
    "    return blocks\n",
    "\n",
    "# -----------------------\n",
    "# 2) Basit kural-tabanlı ayrıştırıcı\n",
    "# -----------------------\n",
    "def parse_blocks_to_merchants(blocks: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Blocks listesinde sırayla gez, merchant entry'lerini tespit et.\n",
    "    Basit heuristic:\n",
    "      - Bir blok ya yeni şirketin başlangıcıdır (genelde başta şirket adı ve adres),\n",
    "      - Eğer \"Core Activity\" veya \"Core Activity\" görünene kadar aynı şirkete ait satırlar ekle.\n",
    "      - \"Branches\" başlığına gelince branches kısmını ayrı olarak kaydet.\n",
    "    \"\"\"\n",
    "    merchants = []\n",
    "    branches_rows = []\n",
    "\n",
    "    current = None  # dict for merchant under construction\n",
    "\n",
    "    def start_new_company(first_lines: List[str]):\n",
    "        return {\n",
    "            \"raw_lines\": list(first_lines),  # to be extended\n",
    "            \"name\": None,\n",
    "            \"address\": None,\n",
    "            \"phones\": [],\n",
    "            \"emails\": [],\n",
    "            \"websites\": [],\n",
    "            \"core_activity\": None,\n",
    "            \"branches_text\": \"\"\n",
    "        }\n",
    "\n",
    "    for blk in tqdm(blocks, desc=\"Parsing blocks\"):\n",
    "        # Basit temizleme\n",
    "        text = blk.strip()\n",
    "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        # Heuristics: eğer blok çok kısa ve \"Branches\" başlığı içeriyorsa branch ekle\n",
    "        if any(BRANCHES_HEADER_RE.search(ln) for ln in lines):\n",
    "            # Eğer daha önceden current yoksa (nadiren) yeni bir entry başlat\n",
    "            if current is None:\n",
    "                current = start_new_company(lines)\n",
    "            # branches kısmını append et\n",
    "            current[\"branches_text\"] += (\"\\n\" + \"\\n\".join(lines))\n",
    "            # branches'i daha sonra parse edeceğiz\n",
    "            continue\n",
    "\n",
    "        # Eğer blok başında ve büyük ihtimalle yeni şirket: satır 0 büyük harfle başlıyorsa (isim) -> yeni şirket\n",
    "        # Bu heuristic yanlış pozitif olabilir; LLM adımı ile düzeltme önerdim.\n",
    "        likely_new_company = False\n",
    "        first_line = lines[0]\n",
    "        # eğer satır büyük bir kelime (Caps veya Baş Harf) ve kısa ise isim olabilir\n",
    "        if len(first_line.split()) <= 7 and re.search(r'[A-Za-z0-9]', first_line):\n",
    "            likely_new_company = True\n",
    "\n",
    "        if current is None:\n",
    "            # yeni şirket başlat\n",
    "            current = start_new_company(lines)\n",
    "            continue\n",
    "\n",
    "        # Eğer mevcut entry varsa, fakat bu blok yeni şirkete benziyorsa mevcut entry'yi finalize edip yeniye başla\n",
    "        if likely_new_company and len(current[\"raw_lines\"]) > 0 and not any(CORE_ACTIVITY_RE.search(l) for l in current[\"raw_lines\"]):\n",
    "            # finalize current\n",
    "            merchants.append(current)\n",
    "            current = start_new_company(lines)\n",
    "            continue\n",
    "\n",
    "        # Aksi takdirde mevcut entry'e ekle\n",
    "        current[\"raw_lines\"].extend(lines)\n",
    "\n",
    "    # döngü bitince kalanı ekle\n",
    "    if current is not None:\n",
    "        merchants.append(current)\n",
    "\n",
    "    # Şimdi her merchant'ın ham satırlarından alanları çıkar\n",
    "    parsed = []\n",
    "    for m in merchants:\n",
    "        text_all = \"\\n\".join(m[\"raw_lines\"])\n",
    "        phones = PHONE_RE.findall(text_all)\n",
    "        emails = EMAIL_RE.findall(text_all)\n",
    "        wws = WWW_RE.findall(text_all)\n",
    "        # www regex döndürdüğü şeyler karmaşık olabilir; uniq yap\n",
    "        websites = sorted(set([w.strip() for w in wws]))\n",
    "        core = None\n",
    "        ca_match = CORE_ACTIVITY_RE.search(text_all)\n",
    "        if ca_match:\n",
    "            core = ca_match.group(1).strip()\n",
    "        # name: ham satırların ilk satırı olma eğiliminde\n",
    "        name_guess = m[\"raw_lines\"][0].strip() if m[\"raw_lines\"] else None\n",
    "        # address guess: ilk 2-3 satırı name'den sonra gelen satırlar arasından telefon/email/web olmayanları al\n",
    "        addr_lines = []\n",
    "        for ln in m[\"raw_lines\"][1:6]:\n",
    "            if PHONE_RE.search(ln) or EMAIL_RE.search(ln) or WWW_RE.search(ln) or CORE_ACTIVITY_RE.search(ln) or BRANCHES_HEADER_RE.search(ln):\n",
    "                continue\n",
    "            addr_lines.append(ln)\n",
    "        address_guess = \", \".join(addr_lines).strip() if addr_lines else None\n",
    "\n",
    "        # branches parsing: eğer branches_text varsa, satır satır parse et; her branch satırı içinde T veya telefon olabilir\n",
    "        branches = []\n",
    "        if m[\"branches_text\"]:\n",
    "            b_lines = [ln for ln in m[\"branches_text\"].splitlines() if ln.strip() and not BRANCHES_HEADER_RE.search(ln)]\n",
    "            # her branch satırını daha küçük alanlara böl ve telefon/email ayıkla\n",
    "            for bl in b_lines:\n",
    "                bphones = PHONE_RE.findall(bl)\n",
    "                bemails = EMAIL_RE.findall(bl)\n",
    "                bwws = WWW_RE.findall(bl)\n",
    "                branches.append({\n",
    "                    \"raw\": bl,\n",
    "                    \"phones\": bphones,\n",
    "                    \"emails\": bemails,\n",
    "                    \"websites\": sorted(set(bwws))\n",
    "                })\n",
    "\n",
    "        parsed.append({\n",
    "            \"name\": name_guess,\n",
    "            \"address\": address_guess,\n",
    "            \"phones\": \";\".join(sorted(set(phones))),\n",
    "            \"emails\": \";\".join(sorted(set(emails))),\n",
    "            \"websites\": \";\".join(websites),\n",
    "            \"core_activity\": core,\n",
    "            \"raw_text\": text_all,\n",
    "            \"branches_struct\": branches\n",
    "        })\n",
    "\n",
    "    # DataFrame oluştur\n",
    "    df_main = pd.DataFrame([{\n",
    "        \"name\": p[\"name\"],\n",
    "        \"address\": p[\"address\"],\n",
    "        \"phones\": p[\"phones\"],\n",
    "        \"emails\": p[\"emails\"],\n",
    "        \"websites\": p[\"websites\"],\n",
    "        \"core_activity\": p[\"core_activity\"],\n",
    "        \"raw_text\": p[\"raw_text\"]\n",
    "    } for p in parsed])\n",
    "\n",
    "    # branches DataFrame: flatten\n",
    "    branches_flat = []\n",
    "    for idx, p in enumerate(parsed):\n",
    "        for b in p[\"branches_struct\"]:\n",
    "            branches_flat.append({\n",
    "                \"merchant_idx\": idx,\n",
    "                \"merchant_name\": p[\"name\"],\n",
    "                \"branch_raw\": b[\"raw\"],\n",
    "                \"branch_phones\": \";\".join(b[\"phones\"]),\n",
    "                \"branch_emails\": \";\".join(b[\"emails\"]),\n",
    "                \"branch_websites\": \";\".join(b[\"websites\"])\n",
    "            })\n",
    "    df_br = pd.DataFrame(branches_flat)\n",
    "\n",
    "    return df_main, df_br\n",
    "\n",
    "# -----------------------\n",
    "# 3) Pipeline çalıştırma\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    blocks = extract_column_blocks(PDF_PATH, n_cols=3)\n",
    "    print(f\"Extracted {len(blocks)} column-blocks.\")\n",
    "    df_main, df_branches = parse_blocks_to_merchants(blocks)\n",
    "    print(\"Parsed merchants:\", len(df_main))\n",
    "    print(\"Parsed branches rows:\", len(df_branches))\n",
    "    df_main.to_csv(OUTPUT_MAIN, index=False, encoding=\"utf-8-sig\")\n",
    "    df_branches.to_csv(OUTPUT_BRANCHES, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Saved CSV files.\")\n"
   ],
   "id": "ccdf2291fe65d0d6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pages: 100%|██████████| 119/119 [00:12<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 332 column-blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing blocks: 100%|██████████| 332/332 [00:00<00:00, 46900.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed merchants: 232\n",
      "Parsed branches rows: 5122\n",
      "Saved CSV files.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def parse_bmf_data(text: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parse BMF Handbook company data into two DataFrames:\n",
    "    1. Companies DataFrame with main company info\n",
    "    2. Branches DataFrame with branch details\n",
    "    \"\"\"\n",
    "    \n",
    "    companies = []\n",
    "    branches = []\n",
    "    \n",
    "    # Split text into company blocks\n",
    "    # Companies typically start with a name followed by address and contact info\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    current_company = None\n",
    "    in_branches = False\n",
    "    branch_lines = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        \n",
    "        # Skip empty lines and page headers/footers\n",
    "        if not line or 'BMF Handbook' in line or line.isdigit():\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Check if this is a \"Branches\" header\n",
    "        if line == 'Branches':\n",
    "            in_branches = True\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Check if this is a \"Core Activity\" line\n",
    "        if line.startswith('Core Activity'):\n",
    "            if current_company:\n",
    "                core_activity = line.replace('Core Activity', '').strip()\n",
    "                current_company['Core Activity'] = core_activity\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Check if line starts with contact info (T, F, E, W)\n",
    "        if re.match(r'^[TFEW]\\s', line):\n",
    "            if current_company:\n",
    "                contact_type = line[0]\n",
    "                contact_value = line[1:].strip()\n",
    "                \n",
    "                if in_branches:\n",
    "                    # This might be a branch phone or additional company contact\n",
    "                    # Check if previous line was a branch name\n",
    "                    if branch_lines:\n",
    "                        last_branch = branch_lines[-1]\n",
    "                        if 'phone' not in last_branch:\n",
    "                            last_branch['phone'] = contact_value\n",
    "                else:\n",
    "                    # Main company contact\n",
    "                    if contact_type == 'T':\n",
    "                        phone_num = 1\n",
    "                        while f'Phone {phone_num}' in current_company:\n",
    "                            phone_num += 1\n",
    "                        current_company[f'Phone {phone_num}'] = contact_value\n",
    "                    elif contact_type == 'F':\n",
    "                        current_company['Fax'] = contact_value\n",
    "                    elif contact_type == 'E':\n",
    "                        email_num = 1\n",
    "                        while f'Email {email_num}' in current_company:\n",
    "                            email_num += 1\n",
    "                        current_company[f'Email {email_num}'] = contact_value\n",
    "                    elif contact_type == 'W':\n",
    "                        web_num = 1\n",
    "                        while f'Website {web_num}' in current_company:\n",
    "                            web_num += 1\n",
    "                        current_company[f'Website {web_num}'] = contact_value\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # If we're in branches section and line doesn't start with T/F/E/W\n",
    "        if in_branches and line:\n",
    "            # Check if this might be a branch name with phone on same line\n",
    "            # Format: \"Branch Name T 01234 567890\" or just \"Branch Name\"\n",
    "            match = re.match(r'^(.+?)(?:\\s+T\\s+(.+))?$', line)\n",
    "            if match:\n",
    "                branch_name = match.group(1).strip()\n",
    "                branch_phone = match.group(2).strip() if match.group(2) else ''\n",
    "                \n",
    "                # Skip if this looks like it's starting a new company\n",
    "                # (usually has more structured address format)\n",
    "                if not re.match(r'^[A-Z][a-z]+$', branch_name) or len(branch_name) > 30:\n",
    "                    branch_lines.append({\n",
    "                        'name': branch_name,\n",
    "                        'phone': branch_phone\n",
    "                    })\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Check if this is a new company (heuristic: line without T/F/E/W prefix)\n",
    "        # and not in branches section\n",
    "        if not in_branches and line and not re.match(r'^[TFEW]\\s', line):\n",
    "            # Save previous company and its branches\n",
    "            if current_company:\n",
    "                companies.append(current_company)\n",
    "                \n",
    "                # Add branches\n",
    "                for branch in branch_lines:\n",
    "                    branches.append({\n",
    "                        'Parent Company': current_company['Company Name'],\n",
    "                        'Branch Name': branch['name'],\n",
    "                        'Branch Phone': branch['phone']\n",
    "                    })\n",
    "            \n",
    "            # Start new company\n",
    "            current_company = {\n",
    "                'Company Name': line,\n",
    "                'Address': '',\n",
    "                'Core Activity': ''\n",
    "            }\n",
    "            branch_lines = []\n",
    "            in_branches = False\n",
    "            \n",
    "            # Try to get address from next lines\n",
    "            j = i + 1\n",
    "            address_lines = []\n",
    "            while j < len(lines):\n",
    "                next_line = lines[j].strip()\n",
    "                if not next_line or re.match(r'^[TFEW]\\s', next_line) or next_line == 'Branches' or next_line.startswith('Core Activity'):\n",
    "                    break\n",
    "                address_lines.append(next_line)\n",
    "                j += 1\n",
    "            \n",
    "            if address_lines:\n",
    "                current_company['Address'] = ', '.join(address_lines)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Don't forget the last company\n",
    "    if current_company:\n",
    "        companies.append(current_company)\n",
    "        for branch in branch_lines:\n",
    "            branches.append({\n",
    "                'Parent Company': current_company['Company Name'],\n",
    "                'Branch Name': branch['name'],\n",
    "                'Branch Phone': branch['phone']\n",
    "            })\n",
    "    \n",
    "    # Create DataFrames\n",
    "    companies_df = pd.DataFrame(companies)\n",
    "    branches_df = pd.DataFrame(branches)\n",
    "    \n",
    "    return companies_df, branches_df\n",
    "\n",
    "\n",
    "def parse_bmf_improved(text: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Improved parser that better handles the multi-column layout\n",
    "    \"\"\"\n",
    "    companies = []\n",
    "    branches = []\n",
    "    \n",
    "    lines = [l.strip() for l in text.split('\\n') if l.strip()]\n",
    "    \n",
    "    i = 0\n",
    "    current_company = None\n",
    "    in_branches = False\n",
    "    temp_branches = []\n",
    "    \n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        \n",
    "        # Skip page markers\n",
    "        if 'BMF Handbook' in line or (line.isdigit() and len(line) <= 3):\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Detect \"Branches\" section\n",
    "        if line == 'Branches':\n",
    "            in_branches = True\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Detect \"Core Activity\"\n",
    "        if line.startswith('Core Activity'):\n",
    "            if current_company:\n",
    "                activity = line.replace('Core Activity', '').strip()\n",
    "                current_company['Core Activity'] = activity\n",
    "            in_branches = False  # After Core Activity, branches section ends\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Detect contact lines (T, F, E, W)\n",
    "        if re.match(r'^[TFEW]\\s+', line):\n",
    "            contact_type = line[0]\n",
    "            value = line[2:].strip()\n",
    "            \n",
    "            if current_company:\n",
    "                if contact_type == 'T':\n",
    "                    n = 1\n",
    "                    while f'Phone {n}' in current_company:\n",
    "                        n += 1\n",
    "                    current_company[f'Phone {n}'] = value\n",
    "                elif contact_type == 'F':\n",
    "                    current_company['Fax'] = value\n",
    "                elif contact_type == 'E':\n",
    "                    n = 1\n",
    "                    while f'Email {n}' in current_company:\n",
    "                        n += 1\n",
    "                    current_company[f'Email {n}'] = value\n",
    "                elif contact_type == 'W':\n",
    "                    n = 1\n",
    "                    while f'Website {n}' in current_company:\n",
    "                        n += 1\n",
    "                    current_company[f'Website {n}'] = value\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # If in branches section, parse branch entries\n",
    "        if in_branches and current_company:\n",
    "            # Branch format: \"Name\" or \"Name T phone\"\n",
    "            if re.match(r'^T\\s+\\d', line):\n",
    "                # Phone for previous branch\n",
    "                if temp_branches and 'phone' not in temp_branches[-1]:\n",
    "                    temp_branches[-1]['phone'] = line[2:].strip()\n",
    "            else:\n",
    "                # New branch name\n",
    "                parts = line.split(' T ')\n",
    "                if len(parts) == 2:\n",
    "                    temp_branches.append({'name': parts[0].strip(), 'phone': parts[1].strip()})\n",
    "                else:\n",
    "                    temp_branches.append({'name': line, 'phone': ''})\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Detect new company (not starting with contact prefix, not \"Branches\" or \"Core Activity\")\n",
    "        if not re.match(r'^[TFEW]\\s+', line) and line not in ['Branches', 'Core Activity']:\n",
    "            # Save previous company\n",
    "            if current_company:\n",
    "                companies.append(current_company)\n",
    "                for br in temp_branches:\n",
    "                    branches.append({\n",
    "                        'Parent Company': current_company['Company Name'],\n",
    "                        'Branch Name': br['name'],\n",
    "                        'Branch Phone': br['phone']\n",
    "                    })\n",
    "                temp_branches = []\n",
    "            \n",
    "            # Start new company\n",
    "            current_company = {\n",
    "                'Company Name': line,\n",
    "                'Address': '',\n",
    "                'Core Activity': ''\n",
    "            }\n",
    "            in_branches = False\n",
    "            \n",
    "            # Collect address lines\n",
    "            addr_lines = []\n",
    "            j = i + 1\n",
    "            while j < len(lines):\n",
    "                next_line = lines[j]\n",
    "                if (re.match(r'^[TFEW]\\s+', next_line) or \n",
    "                    next_line in ['Branches', 'Core Activity'] or\n",
    "                    (not re.match(r'^[TFEW]\\s+', next_line) and \n",
    "                     next_line not in ['Branches', 'Core Activity'] and\n",
    "                     j > i + 3)):  # Assume max 3 address lines\n",
    "                    break\n",
    "                if next_line and not next_line.startswith('BMF'):\n",
    "                    addr_lines.append(next_line)\n",
    "                j += 1\n",
    "            \n",
    "            current_company['Address'] = ', '.join(addr_lines[:3])  # Take max 3 lines\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Save last company\n",
    "    if current_company:\n",
    "        companies.append(current_company)\n",
    "        for br in temp_branches:\n",
    "            branches.append({\n",
    "                'Parent Company': current_company['Company Name'],\n",
    "                'Branch Name': br['name'],\n",
    "                'Branch Phone': br['phone']\n",
    "            })\n",
    "    \n",
    "    companies_df = pd.DataFrame(companies)\n",
    "    branches_df = pd.DataFrame(branches)\n",
    "    \n",
    "    return companies_df, branches_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Test data\n",
    "    test_data = \"\"\"\n",
    "AE Spink Ltd\n",
    "Kelham Street, Doncaster, England DN1 3RA\n",
    "T 01302 321514\n",
    "F 01302 327543\n",
    "E info@aespink.com\n",
    "W www.aespink.com\n",
    "Core Activity General Merchant\n",
    "Branches\n",
    "Doncaster Building Supplies\n",
    "T 01302 554238\n",
    "Doncaster Plumbing & Heating\n",
    "T 01302 554254\n",
    "Leeds Building Supplies\n",
    "T 0113 8591122\n",
    "Leeds Plumbing & Heating\n",
    "T 0113 8592211\n",
    "Sheffield Plumbing & Heating\n",
    "T 0114 3990905\n",
    "Worksop Plumbing & Heating\n",
    "T 01909 484884\n",
    "\n",
    "Allneeds Building & Construction Ltd\n",
    "T/A ABC Depot 248 Regents Park Road, Finchley, England N3 3HN\n",
    "T 0203 1515222\n",
    "E prax.patel@abcdepot.co.uk\n",
    "W www.abcdepot.co.uk\n",
    "Core Activity General Merchant\n",
    "Branches\n",
    "Finchley\n",
    "T 020 8349 9987\n",
    "Hatfield\n",
    "T 020 3151 5222\n",
    "\n",
    "Alsford\n",
    "Ness Road, Erith, England DA8 2LD\n",
    "T 01322 333 088\n",
    "E enquiries@alsfordtimber.com\n",
    "W www.alsfordtimber.com\n",
    "Core Activity General Merchant\n",
    "Branches\n",
    "Beckenham\n",
    "T 020 8655 3939\n",
    "Brighton\n",
    "T 01273 554 888\n",
    "Cobham\n",
    "T 01932 863 468\n",
    "\"\"\"\n",
    "    \n",
    "    companies_df, branches_df = parse_bmf_improved(test_data)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPANIES\")\n",
    "    print(\"=\" * 80)\n",
    "    print(companies_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BRANCHES\")\n",
    "    print(\"=\" * 80)\n",
    "    print(branches_df.to_string(index=False))\n",
    "    \n",
    "    # Save to Excel\n",
    "    with pd.ExcelWriter('bmf_handbook_data.xlsx', engine='openpyxl') as writer:\n",
    "        companies_df.to_excel(writer, sheet_name='Companies', index=False)\n",
    "        branches_df.to_excel(writer, sheet_name='Branches', index=False)\n",
    "    \n",
    "    print(\"\\n✅ Data exported to 'bmf_handbook_data.xlsx'\")"
   ],
   "id": "26da46a374a901f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc98421d97916a44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
